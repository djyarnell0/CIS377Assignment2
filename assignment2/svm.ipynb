{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppport Vector Machines (30 points)\n",
    "\n",
    "A SVM is used for classification or regression. This algorithm goal is to find a hyperplane in N dimensional space that can distinctly classify a certain datapoint. Below are some examples of hyper planes that seperate classes.\n",
    "\n",
    "![svm](images/svm.jpg)\n",
    "\n",
    "This shows a hyperplane that is drawn on the graph. The points on either side of the line are two distinct classes\n",
    "\n",
    "![svm-margin](images/SVM_margin.png)\n",
    "\n",
    "This shows a linear kernel SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for the SVM\n",
    "\n",
    "similiar to the decision tree we need to read in the data and split it into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data and clean the data\n",
    "df = None\n",
    "path = 'loan_defualter.csv'\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# read in csv\n",
    "\n",
    "# there are three columns that are not needed\n",
    "# remove the Surname, CustomerId, and RowNumber columns from the df\n",
    "\n",
    "# There are two columns that are strings Geography and Gender.\n",
    "# Computers can not process strings easily and it's difficult to do math with strings.\n",
    "# The two most common approches to dealing with strings is One Hot Encoding and Label Encoding\n",
    "# Use label encoding to convert these two columns to integer values\n",
    "# use sklearn label encoding function for this\n",
    "\n",
    "#################################END CODE##################################\n",
    "\n",
    "assert(type(df) == pd.DataFrame)\n",
    "assert(df['Gender'].max() == 1)\n",
    "assert(df['Geography'].max() == 2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y= None,None,None,None\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# split the data using train_test_split (set random_state arg to 42, train_size=0.8, test_size=0.2, shuffle=True)\n",
    "\n",
    "#################################END CODE##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data\n",
    "\n",
    "It is better to have the same scale in many optimization methods.\n",
    "\n",
    "Many kernel functions use internally an euclidean distance to compare two different samples (in the gaussian kernel the euclidean distance is in the exponential term), if every feature has a different scale, the euclidean distance only take into account the features with highest scale.\n",
    "\n",
    "You can read more on normalization techniques [here](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02)\n",
    "\n",
    "For most problems I have worked with normalization is done via Standard scaler, MinMax scaler, or the model has data scaling built into their repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the train data (train_x)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import _data\n",
    "\n",
    "scaler = None\n",
    "original_train = train_x\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# assign the scaler to an instance of StandarScaler\n",
    "\n",
    "# Fit the scaler and tranform the data. The train_x variable should now be normalized\n",
    "\n",
    "#################################END CODE##################################\n",
    "assert(type(scaler) == _data.StandardScaler)\n",
    "assert(np.array_equal(original_train,train_x) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "support_vector_classifier = SVC(kernel='rbf')\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# use the support_vector_classifier and train the model on the train data\n",
    "\n",
    "#################################END CODE##################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the SVM\n",
    "\n",
    "Important step for this case is to normalize the test data with the same scaler for the train. The reason is the model expects your test data to be using the same normalization technique. The model is trained with that scale in mind. If you use the raw test data then you won't get accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = test_x\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# normalize the test data using the same scaler used above\n",
    "# use the transform method to transform the data\n",
    "\n",
    "#################################END CODE##################################\n",
    "\n",
    "assert(np.array_equal(original_test,test_x) == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the SVM is trained so now we need to evaluate the model and see how it performs on the test set\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "results_dict = {'Accuracy':0,'Precision':0,'Recall':0}\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# use the SVM to predict on the test data\n",
    "\n",
    "# compare the truth labels with the predicted labels for accuracy, precision, and recall\n",
    "# store the results into the dataframe\n",
    "\n",
    "#################################END CODE##################################\n",
    "\n",
    "assert(results_dict['Accuracy'] > 0.15)\n",
    "assert(results_dict['Precision'] > 0.05)\n",
    "assert(results_dict['Recall'] > 0.30)\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now trained and evaluated a SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize training a SVM\n",
    "\n",
    "Similiar to the decision tree use the plot helper function to graph the svm metrics as it trains. This will tell you if it is overfitting, underfitting or converging properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_helpers import plot_learning_curve\n",
    "svm = SVC(kernel='linear')\n",
    "############################STUDENT CODE GOES HERE#########################\n",
    "# use the plot_learning_curve function to return a graph of your training\n",
    "# this fuction will use cross validation for getting the validation metrics\n",
    "# Hint: you can use the scoring argument and set it to a string to show a certain metric (\"accuracy\",\"precision\",\"recall\")\n",
    "# plot at least one of the metrics\n",
    "\n",
    "#################################END CODE##################################\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now completed the SVM portion of this assignment. Now you have gotten the hang of training and evaluating these models. It is now time for you to run your own experiments and see how well you can get these models to perform."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('CIS377')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cf39ea2468c25ef01d0180ac5c7c5efd34ecf54a919b856e0adf8b71c8868b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
